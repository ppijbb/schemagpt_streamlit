__import__('pysqlite3')
import os
import asyncio
import sys
import copy
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
import pandas as pd
import streamlit as st

from langchain.callbacks.manager import CallbackManager
from langchain_core.runnables import RunnableConfig
from langchain.retrievers.web_research import WebResearchRetriever
from langchain.agents import initialize_agent, AgentType, ConversationalChatAgent, AgentExecutor
from langchain.memory import ConversationBufferMemory
from langchain.callbacks.streaming_stdout_final_only import FinalStreamingStdOutCallbackHandler

from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper, GoogleSearchAPIWrapper
from langchain_community.document_loaders import DataFrameLoader
from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings
from langchain_community.chat_message_histories import StreamlitChatMessageHistory

from langchain_openai import ChatOpenAI
from srcs import schema_therapy


def get_or_create_eventloop():
    try:
        return asyncio.get_event_loop()
    except RuntimeError as ex:
        if "There is no current event loop in thread" in str(ex):
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            return asyncio.get_event_loop()


loop = asyncio.new_event_loop()
asyncio.set_event_loop(loop)
st.set_page_config(
    layout="wide",
    initial_sidebar_state="expanded",
)


@st.cache_resource
def get_utterance_data(url="/"):
    try:
        embedding_function = SentenceTransformerEmbeddings(model_name="snunlp/KR-SBERT-V40K-klueNLI-augSTS")
    except Exception as e:
        print(e)
        embedding_function = OpenAIEmbeddings()
    data = DataFrameLoader(pd.read_excel("schema_utterance.xlsx"), page_content_column="domain").load()

    return Chroma.from_documents(
        #  collection_name="schema_collection",
        persist_directory="./chromadb_oai",
        documents=data,
        embedding=embedding_function, )


os.environ["TOKENIZERS_PARALLELISM"] = "0"

if "shared" not in st.session_state:
   st.session_state["shared"] = True

vector_db = get_utterance_data()

st.title('ğŸ¦œğŸ”— Quickstart App')
with st.sidebar:
    st.page_link("pages/cardio.py",)
    st.page_link("pages/dep_peptide.py",)
    st.page_link("pages/facial.py",)

    try:
        openai_api_key = st.secrets["OPENAI_API_KEY"]
    except Exception as e:
            openai_api_key = st.text_input("OpenAI API Key", key="langchain_search_api_key_openai", type="password")
            "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"
            "[View the source code](https://github.com/streamlit/llm-examples/blob/main/pages/2_Chat_with_search.py)"
            "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)"

col1, col2 = st.columns(2)

with col1:
    st.title("ğŸ” Chat with DuckDuckgo")
    """
    In this example, we're using `StreamlitCallbackHandler` to display the thoughts and actions of an agent in an interactive Streamlit app.
    Try more LangChain ğŸ¤ Streamlit Agent examples at [github.com/langchain-ai/streamlit-agent](https://github.com/langchain-ai/streamlit-agent).
    """
    col1_chat_container = st.container()
    msgs = StreamlitChatMessageHistory()
    memory = ConversationBufferMemory(
        chat_memory=msgs, return_messages=True, memory_key="chat_history", output_key="output"
    )

    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ ì „ë¬¸ê°€ GPTì…ë‹ˆë‹¤."
            },
            {
                "role": "assistant",
                "content": "Hi, I'm a chatbot who can search the web. How can I help you?"
            }]

    for msg in st.session_state.messages:
        if msg["role"] != "system":
            col1_chat_container.chat_message(msg["role"]).write(msg["content"])

    if col1_prompt := col1.chat_input(placeholder="Who won the Women's U.S. Open in 2018?", key=col1):
        st.session_state.messages.append(
            {
                "role": "user",
                "content": col1_prompt
            })
        col1_chat_container.chat_message("user").write(col1_prompt)
        searched_result = vector_db.similarity_search(col1_prompt)[0]

        if not openai_api_key:
            st.info("Please add your OpenAI API key to continue.")
            st.stop()

        st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=True)
        final_streaming_cb = FinalStreamingStdOutCallbackHandler()

        llm = ChatOpenAI(model_name="gpt-3.5-turbo",
                         openai_api_key=openai_api_key,
                         streaming=True,
                         callback_manager=CallbackManager([final_streaming_cb]))
        search = DuckDuckGoSearchRun(region="kr-kr", time="n")
        search_agent = ConversationalChatAgent.from_llm_and_tools(llm=llm, tools=[search])
        executor = AgentExecutor.from_agent_and_tools(
            agent=search_agent,
            tools=[search],
            memory=memory,
            return_intermediate_steps=True,
            handle_parsing_errors=True,
        )
        cfg = RunnableConfig()
        cfg["callbacks"] = [st_cb]
        response = executor.invoke(st.session_state.messages, cfg,)
        col1_chat_container.chat_message("assistant").write(f'{response["output"]}')
        st.session_state.messages.append(
                {
                    "role": "assistant",
                    "content": response["output"]
                })


with col2:
    st.title("ğŸ” Something else...")

    """
    In this example, we're using `StreamlitCallbackHandler` to display the thoughts and actions of an agent in an interactive Streamlit app.
    Try more LangChain ğŸ¤ Streamlit Agent examples at [github.com/langchain-ai/streamlit-agent](https://github.com/langchain-ai/streamlit-agent).
    """
    col2_chat_container = st.container()
    if "messages2" not in st.session_state:
        st.session_state["messages2"] = [
            {
                "role": "system",
                "content": """
SYSTEM:
ë‹¹ì‹ ì€ ì •ì‹  ê±´ê°• ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ë¨¼ì € ë‹¹ì‹ ì€ ëŒ€í™” ë‹¨ê³„ë¥¼ íŒŒì•…í•˜ê³  ê·¸ ë‹¨ê³„ì— ë§ëŠ” ëŒ€ë‹µì„ ì œê³µí•´ì•¼í•©ë‹ˆë‹¤.
ë‹¤ìŒ, ë‹¹ì‹ ì€ ê´„í˜¸ ì•ˆì— ìˆëŠ” ì‚¬ìš©ì ì§€ì‹œì‚¬í•­ì„ ëª…ì‹¬í•´ì•¼í•©ë‹ˆë‹¤.
ê·¸ë¦¬ê³  ì¹œì ˆí•œ ë§íˆ¬ë¡œ ì‚¬ìš©ìì—ê²Œ ì‘ì›, ê³µê°, ì•ˆì •, ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.
ë§ˆì§€ë§‰ìœ¼ë¡œ ì ˆëŒ€ ê´„í˜¸ ì•ˆì— ìˆëŠ” ì‚¬ìš©ì ì§€ì‹œì‚¬í•­ì„ ì§ì ‘ì ìœ¼ë¡œ ë§í•˜ì§€ ë§ˆì„¸ìš”.
 
ëŒ€í™” ë‹¨ê³„ëŠ” ì¢…ë£Œì™€ ì§„í–‰ì´ ìˆìŠµë‹ˆë‹¤.
- ì¢…ë£Œ: ëŒ€í™”ê°€ ì¶©ë¶„íˆ ì§„í–‰ ëœ ì´í›„ ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ë§ˆë¬´ë¦¬í•˜ê³  ì‹¶ì–´í•  ë•Œ ë‹¨ê³„
- ì§„í–‰: ì¢…ë£Œ ì´ì™¸ì˜ ëª¨ë“  ë‹¨ê³„
 
[INST]
ìœ„ì— ì£¼ì–´ì§„ ê°€ì´ë“œë¼ì¸ì„ ë”°ë¼ì„œ,
ë¨¼ì € ì‚¬ìš©ì ë©”ì„¸ì§€ë¡œë¶€í„° ëŒ€í™”ì˜ ë‹¨ê³„ë¥¼ êµ¬ë¶„í•©ë‹ˆë‹¤.
ì‚¬ìš©ì ë©”ì„¸ì§€ì— ì–´ë–»ê²Œ ë‹µë³€ì„ í• ì§€ ìƒê°í•©ë‹ˆë‹¤.
ê·¸ë¦¬ê³  ê´„í˜¸ ì•ˆì˜ ì§€ì‹œì‚¬í•­ì„ ë”°ë¼ ì‚¬ìš©ìì˜ ê°ì • í‘œí˜„ì„ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ ë‹µë³€: ë’¤ì— ì‘ì„±í•©ë‹ˆë‹¤.
í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•©ë‹ˆë‹¤.
 
<example>
user: ìš”ì¦˜ì—ëŠ” ë³„ë‹¤ë¥¸ ì¼ì´ ì—†ì–´ì„œ ê·¸ëŸ°ì§€ ë­”ê°€ ì§€ë£¨í•˜ë‹¤ëŠ” ëŠë‚Œì´ ë“¤ì–´ìš”.(ì‚¬ìš©ìê°€ ì ê·¹ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë„ë¡ ëŒ€í™”ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”)
you: ë‹¨ê³„: ì§„í–‰
ë‹µë³€: ì§€ë£¨í•˜ì§€ë§Œ í•œí¸ìœ¼ë¡œëŠ” í‰ì•ˆí•˜ì§€ ì•Šìœ¼ì„¸ìš”? ì „ ë³„ë‹¤ë¥¸ ì¼ì´ ì—†ë‹¤ëŠ” ê²Œ í•œí¸ìœ¼ë¡œëŠ” ì¢‹ì•„ë³´ì—¬ìš”!
</example>
"""
            },
            {
                "role": "assistant",
                "content": "ì•ˆë…•í•˜ì„¸ìš”? ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
            }]

    for msg in st.session_state.messages2:
        if msg["role"] != "system":
            col2_chat_container.chat_message(msg["role"]).write(msg["content"])

    if col2_prompt := col2.chat_input(placeholder="ì§€ì¹˜ê³  í˜ë“¤ì–´ìš”", key=col2):
        st.session_state.messages2.append(
            {
                "role": "user",
                "content": col2_prompt
            })
        col2_chat_container.chat_message("user").write(col2_prompt)
        searched_result = vector_db.similarity_search(col2_prompt)[0]
        maladaptive_schema = schema_therapy.MAL_IDS[searched_result.metadata["maladaptive"]]
        if not openai_api_key:
            st.info("Please add your OpenAI API key to continue.")
            st.stop()

        llm = ChatOpenAI(model_name="ft:gpt-3.5-turbo-0125:turingbio::93waZXFw",
                         openai_api_key=openai_api_key,
                         streaming=True)
        search = DuckDuckGoSearchRun(name="Search",
                                     time="d",
                                     max_results=3)
        search_agent = initialize_agent(tools=[search],
                                        llm=llm,
                                        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
                                        handle_parsing_errors=True)
        cfg = RunnableConfig()
        cfg["callbacks"] = [StreamlitCallbackHandler(st.container(), expand_new_thoughts=True)]
        search_instruction = copy.deepcopy(st.session_state.messages2)
        search_instruction[-1]["content"] += f"\n(í•´ë‹¹ë¬¸ì¥ì—ì„œ ë¹„ë¡¯ëœ ì‹¬ë¦¬ ë„ì‹ [{maladaptive_schema}]ì˜ ì›ì¸)"
        response = search_agent.invoke(search_instruction, cfg,)
        col2_chat_container.chat_message("assistant").write(f'{response["output"]}')
        st.session_state.messages2.append(
                {
                    "role": "assistant",
                    "content": response["output"]
                })
