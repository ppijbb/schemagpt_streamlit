import asyncio
import copy
import streamlit as st
import torch

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_openai import ChatOpenAI

from srcs import schema_therapy
from srcs.graph.agent_common import (
    build_search_tools,
    create_search_agent,
    invoke_agent,
)
from srcs.st_cache import get_utterance_data

loop = asyncio.new_event_loop()
asyncio.set_event_loop(loop)


if __name__ == "__main__":
    st.set_page_config(page_title="chat app",
                       page_icon="ğŸ¤–",
                       layout="wide",
                       initial_sidebar_state="auto",)
    vector_db = get_utterance_data()
    st.title('ğŸ¤– LLM based Chatbot App')
    st.markdown('''

            ## í”„ë¡œì íŠ¸ ì†Œê°œ

                Schema therapy ê¸°ë°˜ ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡
                RAG + ReAct ì‹¬ë¦¬ë„ì‹ ë¶„ì„ìœ¼ë¡œ ìš°ìš¸ê°ì˜ ì›ì¸ ì¶”ë¡ 
                               

            ## ê°œë°œ ë‚´ìš©
            - ìš°ìš¸ì¦ ì±„íŒ… ë¬¸ì§„ ì§„í–‰ ì¤‘ ë°œí™”ìì˜ ê°ì •ì„ ì¶”ì í•˜ì—¬ ì •í™•í•œ ìƒíƒœ í‰ê°€ë¥¼ ì§„í–‰í•˜ëŠ” App ê°œë°œ
            - LLM, NLP(Natural Language Process) ëª¨ë¸, ì–¼êµ´ ê°ì • ì¸ì‹ ëª¨ë¸ ì—°êµ¬ ë° ê°œë°œ
            - ML ì„œë¹„ìŠ¤ë¥¼ ìœ„í•œ FastAPI ë°±ì—”ë“œ ê°œë°œ ë° AWS EC2 ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
            
            ### NLP
            - ì±„íŒ… ì¤‘ ì‚¬ìš©ì ë°œí™”ì˜ ì‹¬ë¦¬ë„ì‹ ë¶„ì„ì„ ìœ„í•œ ë£°ë² ì´ìŠ¤ ì±„íŒ… í”„ë¡œì„¸ìŠ¤ ê¸°íš
            - ìì—°ì–´ ë¶„ì„ì„ í†µí•œ ì±„íŒ… í”„ë¡œì„¸ìŠ¤ ëª©ì ì— ë§ëŠ” 8ê°œ task Finetuning ëª¨ë¸ í•™ìŠµ
                  ê°ì„± ë¶„ë¥˜
                  ë¬¸ì§„ ì‘ë‹µ í‰ê°€
                  ìš°ìš¸ í‚¤ì›Œë“œ ë¶„ë¥˜
                  ì‘ë‹µ ë°œí™” ìƒì„±
                  ë¬¸ì§„ ì§ˆë¬¸ ìƒì„±
                  STS í…ìŠ¤íŠ¸ ì„ë² ë”©
                  ë°œí™” ì´í•´ë¥¼ ìœ„í•œ NLI
                  ë¬¸ì¥ ê°ì„± ë ˆë²¨ í‰ê°€ ëª¨ë¸
            - ì´ˆê¸° í•™ìŠµí•œ ë¬¸ì§„ ì§ˆë¬¸ ìƒì„± ëª¨ë¸ê³¼ ì‘ë‹µ ë°œí™” ìƒì„± ëª¨ë¸ì€ LLMì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
            - ìš°ìš¸ ë¬¸ì§„ì— ì í•©í•œ ì±„íŒ…ì„ í•  ìˆ˜ ìˆëŠ” Prompt Engineering + Fine tuning
            - í˜„ì¬ ë²„ì „ì—ì„œëŠ” LangGraph ê¸°ë°˜ ReAct agent ì‚¬ìš©
            
            ### BackEnd
            - MySQL DB ì‚¬ìš©
            - FastAPI + Gunicorn ë°±ì—”ë“œ ê°œë°œ ë° ì„œë¹„ìŠ¤
            - AWS í´ë¼ìš°ë“œ ì•„í‚¤í…ì²˜ ì„¤ê³„


            ## ì‚¬ìš© ê¸°ìˆ 
            <img src="https://img.shields.io/badge/python-3776AB?style=for-the-badge&logo=python&logoColor=white">
            <img src="https://img.shields.io/badge/github-181717?style=for-the-badge&logo=github&logoColor=white">
            <img src="https://img.shields.io/badge/fastapi-009688?style=for-the-badge&logo=fastapi&logoColor=white"> 
            <img src="https://img.shields.io/badge/numpy-013243?style=for-the-badge&logo=numpy&logoColor=black">
            <img src="https://img.shields.io/badge/pytorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=black"> 
            ''', unsafe_allow_html=True)
    st.image("pages/image/llm_app/architecture.jpg")

    if "shared" not in st.session_state:
        st.session_state["shared"] = True

    with st.sidebar:
        try:
            openai_api_key = st.secrets["OPENAI_API_KEY"]
        except Exception:
            openai_api_key = st.text_input("OpenAI API Key", key="langchain_search_api_key_openai", type="password")
            "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"
            "[View the source code](https://github.com/streamlit/llm-examples/blob/main/pages/2_Chat_with_search.py)"
            "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)"

    CHAT_MAX_MESSAGES = 21

    st.title("Langchain Version")
    col1, col2 = st.columns(2)

    with col1:
        st.title("ğŸ” DDG GPT")
        st.caption("DuckDuckGo ê²€ìƒ‰ ì—”ì§„ì„ í†µí•œ ì‘ë‹µ")
        col1_chat_container = st.container()
        msgs = StreamlitChatMessageHistory()
        if len(msgs.messages) == 0 or st.sidebar.button("Reset chat history"):
            msgs.clear()
            msgs.add_message(SystemMessage(content="ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê³  ì¢…í•©ì  ì •ë³´ë§Œ ìš”ì•½í•´ ì „ë‹¬í•˜ì„¸ìš”."))
            msgs.add_ai_message("ë¬´ì—‡ì„ ì•Œë ¤ë“œë¦´ê¹Œìš”?")
        avatars = {"human": "user", "ai": "assistant", "system": "system"}
        for msg in msgs.messages:
            if msg.type != "system":
                with col1_chat_container.chat_message(avatars[msg.type]):
                    st.write(msg.content)

        if prompt := col1.chat_input(placeholder="ê²½ë³µê¶ì˜ ìœ„ì¹˜ëŠ”?", key=col1):
            col1_chat_container.chat_message("user").write(prompt)
            if not openai_api_key:
                st.info("Please add your OpenAI API key to continue.")
                st.stop()
            llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=openai_api_key, temperature=0)
            tools = build_search_tools(include_arxiv=True, ddg_max_results=10)
            agent = create_search_agent(llm, tools)
            history = list(msgs.messages)[-(CHAT_MAX_MESSAGES - 1) :] + [
                HumanMessage(content=prompt)
            ]
            try:
                response_text = invoke_agent(agent, history)
                msgs.add_user_message(prompt)
                msgs.add_ai_message(response_text)
                if len(msgs.messages) > CHAT_MAX_MESSAGES:
                    system_msgs = [m for m in msgs.messages if getattr(m, "type", None) == "system"]
                    rest = [
                        m
                        for m in msgs.messages
                        if getattr(m, "type", None) != "system"
                    ][-(CHAT_MAX_MESSAGES - len(system_msgs)) :]
                    msgs.messages = system_msgs + rest
                col1_chat_container.chat_message("assistant").write(response_text)
            except Exception as e:
                st.toast(f"An error occurred: {e}")

    with col2:
        st.title("ğŸ¤¸ Schema GPT")
        st.caption("Schema Therapy ê¸°ë°˜ ì •ì‹  ê±´ê°• ì±—ë´‡")
        col2_chat_container = st.container()
        if "messages2" not in st.session_state:
            st.session_state["messages2"] = [
                {"role": "system", "content": schema_therapy.system_prompt},
                {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”?"},
            ]

        for msg in st.session_state.messages2:
            if msg["role"] != "system":
                col2_chat_container.chat_message(msg["role"]).write(msg["content"])

        if col2_prompt := col2.chat_input(placeholder="ì§€ì¹˜ê³  í˜ë“¤ì–´ìš”", key=col2):
            st.session_state.messages2.append({"role": "user", "content": col2_prompt})
            col2_chat_container.chat_message("user").write(col2_prompt)
            with torch.inference_mode():
                searched_result = vector_db.get_relevant_documents(col2_prompt)[0]
                maladaptive_schema = schema_therapy.MAL_IDS[searched_result.metadata["maladaptive"]]

            if not openai_api_key:
                st.info("Please add your OpenAI API key to continue.")
                st.stop()

            llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=openai_api_key, temperature=0)
            tools = build_search_tools(
                include_arxiv=True,
                ddg_max_results=20,
                ddg_time="d",
            )
            agent = create_search_agent(llm, tools)
            search_instruction = copy.deepcopy(st.session_state.messages2)
            search_instruction[-1]["content"] += f"\n(ì‹¬ë¦¬ë„ì‹ [{maladaptive_schema}])"
            try:
                response_text = invoke_agent(agent, search_instruction)
                st.session_state.messages2.append({"role": "assistant", "content": response_text})
                if len(st.session_state.messages2) > CHAT_MAX_MESSAGES:
                    system_msg = next(
                        (m for m in st.session_state.messages2 if m["role"] == "system"), None
                    )
                    rest = [
                        m
                        for m in st.session_state.messages2
                        if m["role"] != "system"
                    ][-(CHAT_MAX_MESSAGES - 1) :]
                    st.session_state.messages2 = ([system_msg] if system_msg else []) + rest
                col2_chat_container.chat_message("assistant").write(response_text)
            except Exception as e:
                st.toast(f"An error occurred: {e}")
