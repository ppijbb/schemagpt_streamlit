# __import__('pysqlite3')
import os
import asyncio
import sys
import copy
import signal
import time
import json
# sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
# os.environ["STREAMLIT_SERVER_ENABLE_STATIC_SERVING"] = "1"
# os.environ["TOKENIZERS_PARALLELISM"] = "0"

# from srcs.app_static_file_handler import AppStaticFileHandler

# sys.modules["streamlit.web.server.app_static_file_handler"].AppStaticFileHandler = AppStaticFileHandler

import pandas as pd
import streamlit as st

from langchain.callbacks.manager import CallbackManager
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import SystemMessage
from langchain.retrievers.web_research import WebResearchRetriever
from langchain.agents import initialize_agent, load_tools
from langchain.agents import AgentType, ConversationalChatAgent, AgentExecutor, Tool
from langchain.agents.loading import AGENT_TO_CLASS, load_agent
from langchain.memory import ConversationBufferMemory
from langchain.callbacks.streaming_stdout_final_only import FinalStreamingStdOutCallbackHandler

from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.tools import DuckDuckGoSearchRun, BingSearchRun, WikipediaQueryRun
from langchain_community.tools.pubmed.tool import PubmedQueryRun
from langchain_community.utilities import (DuckDuckGoSearchAPIWrapper, GoogleSearchAPIWrapper, BingSearchAPIWrapper,
                                           SerpAPIWrapper, WikipediaAPIWrapper, PubMedAPIWrapper)
# from langchain_community.utilities.pubmed import PubMedAPIWrapper

from langchain_community.chat_message_histories import StreamlitChatMessageHistory

from langchain_openai import ChatOpenAI
from ionic_langchain.tool import IonicTool

from srcs import schema_therapy
from srcs.st_cache import get_utterance_data, get_or_create_eventloop


loop = asyncio.new_event_loop()
asyncio.set_event_loop(loop)


if __name__ == "__main__":
    st.set_page_config(page_title="chat app",
                       page_icon="ğŸ¤–",
                       layout="wide",
                       initial_sidebar_state="auto",)
    vector_db = get_utterance_data()
    st.title('ğŸ¤– LLM based Chatbot App')
    st.markdown('''

            ## í”„ë¡œì íŠ¸ ì†Œê°œ

                Schema therapy ê¸°ë°˜ ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡
                RAG ì ìš© ì‹¬ë¦¬ë„ì‹ ê¸°ë°˜ ìš°ìš¸ê°ì˜ ì›ì¸ ì¶”ë¡ 
                               

            ## ê°œë°œ ë‚´ìš©
            - ìš°ìš¸ì¦ ì±„íŒ… ë¬¸ì§„ ì§„í–‰ ì¤‘ ë°œí™”ìì˜ ê°ì •ì„ ì¶”ì í•˜ì—¬ ì •í™•í•œ ìƒíƒœ í‰ê°€ë¥¼ ì§„í–‰í•˜ëŠ” App ê°œë°œ
            - LLM, NLP(Natural Language Process) ëª¨ë¸, ì–¼êµ´ ê°ì • ì¸ì‹ ëª¨ë¸ ì—°êµ¬ ë° ê°œë°œ
            - ML ì„œë¹„ìŠ¤ë¥¼ ìœ„í•œ FastAPI ë°±ì—”ë“œ ê°œë°œ ë° AWS EC2 ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
            
            ### NLP
            - ì±„íŒ… ì¤‘ ì‚¬ìš©ì ë°œí™”ì˜ ì‹¬ë¦¬ë„ì‹ ë¶„ì„ì„ ìœ„í•œ ë£°ë² ì´ìŠ¤ ì±„íŒ… í”„ë¡œì„¸ìŠ¤ ê¸°íš
            - ìì—°ì–´ ë¶„ì„ì„ í†µí•œ ì±„íŒ… í”„ë¡œì„¸ìŠ¤ ëª©ì ì— ë§ëŠ” 8ê°œ task Finetuning ëª¨ë¸ í•™ìŠµ
                  ê°ì„± ë¶„ë¥˜
                  ë¬¸ì§„ ì‘ë‹µ í‰ê°€
                  ìš°ìš¸ í‚¤ì›Œë“œ ë¶„ë¥˜
                  ì‘ë‹µ ë°œí™” ìƒì„±
                  ë¬¸ì§„ ì§ˆë¬¸ ìƒì„±
                  STS í…ìŠ¤íŠ¸ ì„ë² ë”©
                  ë°œí™” ì´í•´ë¥¼ ìœ„í•œ NLI
                  ë¬¸ì¥ ê°ì„± ë ˆë²¨ í‰ê°€ ëª¨ë¸
            - ì´ˆê¸° í•™ìŠµí•œ ë¬¸ì§„ ì§ˆë¬¸ ìƒì„± ëª¨ë¸ê³¼ ì‘ë‹µ ë°œí™” ìƒì„± ëª¨ë¸ì€ LLMì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
            - ìš°ìš¸ ë¬¸ì§„ì— ì í•©í•œ ì±„íŒ…ì„ í•  ìˆ˜ ìˆëŠ” Prompt Engineering + Fine tuning
            
            ### BackEnd
            - MySQL DB ì‚¬ìš©
            - FastAPI + Gunicorn ë°±ì—”ë“œ ê°œë°œ ë° ì„œë¹„ìŠ¤
            - AWS í´ë¼ìš°ë“œ ì•„í‚¤í…ì²˜ ì„¤ê³„


            ## ì‚¬ìš© ê¸°ìˆ 
            <img src="https://img.shields.io/badge/python-3776AB?style=for-the-badge&logo=python&logoColor=white">
            <img src="https://img.shields.io/badge/github-181717?style=for-the-badge&logo=github&logoColor=white">
            <img src="https://img.shields.io/badge/fastapi-009688?style=for-the-badge&logo=fastapi&logoColor=white"> 
            <img src="https://img.shields.io/badge/numpy-013243?style=for-the-badge&logo=numpy&logoColor=black">
            <img src="https://img.shields.io/badge/pytorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=black"> 
            ''', unsafe_allow_html=True)
    st.image("pages/image/llm_app/architecture.jpg")

    if "shared" not in st.session_state:
        st.session_state["shared"] = True

    with st.sidebar:
        # st.page_link("pages/cardio.py",)
        # st.page_link("pages/dep_peptide.py",)
        # st.page_link("pages/facial.py",)

        try:
            openai_api_key = st.secrets["OPENAI_API_KEY"]
        except Exception as e:
                openai_api_key = st.text_input("OpenAI API Key", key="langchain_search_api_key_openai", type="password")
                "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"
                "[View the source code](https://github.com/streamlit/llm-examples/blob/main/pages/2_Chat_with_search.py)"
                "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)"

    st.title("Langchain Version")
    col1, col2 = st.columns(2)
    
    with col1:
        st.title("ğŸ” DDG GPT")
        """
        DuckDuckGo ê²€ìƒ‰ ì—”ì§„ì„ í†µí•œ ì‘ë‹µ
        """
        col1_chat_container = st.container()
        msgs = StreamlitChatMessageHistory()
        memory = ConversationBufferMemory(chat_memory=msgs,
                                          return_messages=True,
                                          memory_key="chat_history",
                                          output_key="output")
        if len(msgs.messages) == 0 or st.sidebar.button("Reset chat history"):
            msgs.clear()
            msgs.add_message(SystemMessage(content="ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê³  ì¢…í•©ì  ì •ë³´ë§Œ ìš”ì•½í•´ ì „ë‹¬í•˜ì„¸ìš”."))
            msgs.add_ai_message("ë¬´ì—‡ì„ ì•Œë ¤ë“œë¦´ê¹Œìš”?")
            st.session_state.steps = {}
        avatars = {"human": "user", "ai": "assistant", "system": "system"}
        for idx, msg in enumerate(msgs.messages):
            if msg.type != "system":
                with col1_chat_container.chat_message(avatars[msg.type]):
                    # Render intermediate steps if any were saved
                    for step in st.session_state.steps.get(str(idx), []):
                        if step[0].tool == "_Exception":
                            continue
                        with st.status(f"**{step[0].tool}**: {step[0].tool_input}", state="complete"):
                            st.write(step[0].log)
                            st.write(step[1])
                    st.write(msg.content)

        if prompt := col1.chat_input(placeholder="ê²½ë³µê¶ì˜ ìœ„ì¹˜ëŠ”?", key=col1):
            col1_chat_container.chat_message("user").write(prompt)

            if not openai_api_key:
                st.info("Please add your OpenAI API key to continue.")
                st.stop()

            llm = ChatOpenAI(model_name="gpt-3.5-turbo",
                             openai_api_key=openai_api_key,
                             streaming=True)
            tools = [
                DuckDuckGoSearchRun(
                    api_wrapper=DuckDuckGoSearchAPIWrapper(max_results=10, 
                                                           region="en-en")),
                DuckDuckGoSearchRun(
                    api_wrapper=DuckDuckGoSearchAPIWrapper(max_results=10, 
                                                           region="kr-kr")),
                WikipediaQueryRun(
                    api_wrapper=WikipediaAPIWrapper()),
                PubmedQueryRun(
                    api_wrapper=PubMedAPIWrapper()),
                IonicTool().tool()
                ] + load_tools(["arxiv"],)
            chat_agent = ConversationalChatAgent.from_llm_and_tools(llm=llm,
                                                                    tools=tools)
            executor = AgentExecutor.from_agent_and_tools(agent=chat_agent,
                                                          tools=tools,
                                                          memory=memory,
                                                          max_iterations=3,
                                                          early_stopping_method="generate",
                                                          return_intermediate_steps=True,
                                                          handle_parsing_errors=True,)
            cfg = RunnableConfig()
            cfg["callbacks"] = [StreamlitCallbackHandler(st.container(), expand_new_thoughts=True)]
            response = executor.invoke(prompt, cfg)
            st.session_state.steps[str(len(msgs.messages) - 1)] = response["intermediate_steps"]
            col1_chat_container.chat_message("assistant").write(response["output"])

    with col2:
        st.title("ğŸ¤¸ Schema GPT")
        """
        Schema Therapy ê¸°ë°˜ ì •ì‹  ê±´ê°• ì±—ë´‡ 
        """
        col2_chat_container = st.container()
        if "messages2" not in st.session_state:
            st.session_state["messages2"] = [
                {
                    "role": "system",
                    "content": schema_therapy.system_prompt
                },
                {
                    "role": "assistant",
                    "content": "ì•ˆë…•í•˜ì„¸ìš”? ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”?"
                }]

        for msg in st.session_state.messages2:
            if msg["role"] != "system":
                col2_chat_container.chat_message(msg["role"]).write(msg["content"])

        if col2_prompt := col2.chat_input(placeholder="ì§€ì¹˜ê³  í˜ë“¤ì–´ìš”", key=col2):
            st.session_state.messages2.append(
                {
                    "role": "user",
                    "content": col2_prompt
                })
            col2_chat_container.chat_message("user").write(col2_prompt)
            searched_result = vector_db.similarity_search(col2_prompt)[0]
            maladaptive_schema = schema_therapy.MAL_IDS[searched_result.metadata["maladaptive"]]
            if not openai_api_key:
                st.info("Please add your OpenAI API key to continue.")
                st.stop()

            llm = ChatOpenAI(model_name="gpt-3.5-turbo",#"ft:gpt-3.5-turbo-0125:turingbio::93waZXFw",
                             openai_api_key=openai_api_key,
                             streaming=True)
            tools = [DuckDuckGoSearchRun(
                        api_wrapper=DuckDuckGoSearchAPIWrapper(time="d",
                                                               region="kr-kr",
                                                               max_results=20)),
                     DuckDuckGoSearchRun(
                        api_wrapper=DuckDuckGoSearchAPIWrapper(time="d",
                                                               region="en-en",
                                                               max_results=20)),
                     WikipediaQueryRun(
                        api_wrapper=WikipediaAPIWrapper()),
                     PubmedQueryRun(),
                     IonicTool().tool()] + load_tools(["arxiv"],)
            search_agent = initialize_agent(tools=tools,
                                            llm=llm,
                                            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
                                            # agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
                                            handle_parsing_errors=True,
                                            max_iterations=5,
                                            early_stopping_method="generate",
                                            return_intermediate_steps=True,
                                            agent_kwargs={
                                                # "format_instructions": schema_therapy.format_instructions,
                                                "system_message_prefix": schema_therapy.prefix_prompt,
                                                "system_message_suffix": schema_therapy.suffix_prompt
                                                }
                                            # max_execution_time=15
                                            )
            # st.write(search_agent.agent.__dir__())

            # st.write(AGENT_TO_CLASS[AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION])
            # st.write(search_agent.agent.tool_run_logging_kwargs())
            with col2_chat_container.chat_message("assistant"):
                cfg = RunnableConfig()
                message_placeholder = st.empty()
                cfg["callbacks"] = [StreamlitCallbackHandler(st.container(), expand_new_thoughts=True)]
                search_instruction = copy.deepcopy(st.session_state.messages2)
                search_instruction[-1]["content"] += f"\n(í•´ë‹¹ë¬¸ì¥ì— ëŒ€í•œí•œ ì‹¬ë¦¬ ë„ì‹ [{maladaptive_schema}] schema therapy strategy)"
                response = search_agent.invoke(search_instruction, cfg, chat_history=st.session_state.messages2)
                # st.write(response)
                output = json.loads(response["output"])["action_input"] if "{" in response["output"]  else response["output"]
                full_msg = ""
                for o in output:
                    full_msg += o
                    message_placeholder.markdown(f'{full_msg}â–Œ')
                message_placeholder.markdown(full_msg)
                st.session_state.messages2.append(
                        {
                            "role": "assistant",
                            "content": output
                        })
