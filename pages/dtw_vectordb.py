# __import__('pysqlite3')
import os
import asyncio
import sys
import copy
import signal
import time
import json
# sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
# os.environ["STREAMLIT_SERVER_ENABLE_STATIC_SERVING"] = "1"
# os.environ["TOKENIZERS_PARALLELISM"] = "0"

# from srcs.app_static_file_handler import AppStaticFileHandler

# sys.modules["streamlit.web.server.app_static_file_handler"].AppStaticFileHandler = AppStaticFileHandler

import pandas as pd
import streamlit as st

from langchain.callbacks.manager import CallbackManager
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import SystemMessage
from langchain.retrievers.web_research import WebResearchRetriever
from langchain.agents import initialize_agent, load_tools
from langchain.agents import AgentType, ConversationalChatAgent, AgentExecutor, Tool
from langchain.agents.loading import AGENT_TO_CLASS, load_agent
from langchain.memory import ConversationBufferMemory
from langchain.callbacks.streaming_stdout_final_only import FinalStreamingStdOutCallbackHandler

from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.tools import DuckDuckGoSearchRun, BingSearchRun, WikipediaQueryRun
from langchain_community.tools.pubmed.tool import PubmedQueryRun
from langchain_community.utilities import (DuckDuckGoSearchAPIWrapper, GoogleSearchAPIWrapper, BingSearchAPIWrapper,
                                           SerpAPIWrapper, WikipediaAPIWrapper, PubMedAPIWrapper)

from langchain_community.chat_message_histories import StreamlitChatMessageHistory

from langchain_openai import ChatOpenAI
from ionic_langchain.tool import IonicTool

from srcs.st_cache import get_audio_data, get_or_create_eventloop


loop = asyncio.new_event_loop()
asyncio.set_event_loop(loop)


if __name__ == "__main__":
    st.set_page_config(page_title="audio retriver app",
                       page_icon="ğŸ¼",
                       layout="wide",
                       initial_sidebar_state="auto",)
    vector_db = get_audio_data()
    st.title('ğŸ¼ Audio DTW DB App')
    st.markdown('''

            ## í”„ë¡œì íŠ¸ ì†Œê°œ

                chromadb ê¸°ë°˜ audio mfcc dtw db
                ìœ ì‚¬ ì‚¬ìš´ë“œ ê²€ìƒ‰ 
                               

            ## ê°œë°œ ë‚´ìš©
            - ChromaDB ìˆ˜ì •í•˜ì—¬ custom embedding function, distance function ì¶”ê°€
            - ì¶”ê°€ëœ embedding function : ì‚¬ìš´ë“œ ë°ì´í„° -> mfcc ë¡œ ì €ì¥
            - ì¶”ê°€ëœ distance function : mfcc -> dtw ë¥¼ scoreë¡œ ê³„ì‚°
            
            ### BackEnd
            - FastAPI + Gunicorn ë°±ì—”ë“œ ê°œë°œ ë° ì„œë¹„ìŠ¤
            - Docker + goofys í†µí•œ s3 ë°ì´í„° ì²˜ë¦¬


            ## ì‚¬ìš© ê¸°ìˆ 
            <img src="https://img.shields.io/badge/python-3776AB?style=for-the-badge&logo=python&logoColor=white">
            <img src="https://img.shields.io/badge/github-181717?style=for-the-badge&logo=github&logoColor=white">
            <img src="https://img.shields.io/badge/fastapi-009688?style=for-the-badge&logo=fastapi&logoColor=white"> 
            <img src="https://img.shields.io/badge/numpy-013243?style=for-the-badge&logo=numpy&logoColor=black">

            ''', unsafe_allow_html=True)

    if "shared" not in st.session_state:
        st.session_state["shared"] = True

    with st.sidebar:
        # st.page_link("pages/cardio.py",)
        # st.page_link("pages/dep_peptide.py",)
        # st.page_link("pages/facial.py",)

        try:
            openai_api_key = st.secrets["OPENAI_API_KEY"]
        except Exception as e:
                openai_api_key = st.text_input("OpenAI API Key", key="langchain_search_api_key_openai", type="password")
                "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"
                "[View the source code](https://github.com/streamlit/llm-examples/blob/main/pages/2_Chat_with_search.py)"
                "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)"

    st.title("Langchain Version")
    """
    MFCC-DTW ìŒì› ê²€ìƒ‰
    """
    chat_container = st.container()
    st.file_uploader("ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ìŒì•… ìŠ¤íƒ€ì¼", type=["wav", "mp3"])
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ìµœì‹  ìŒì•…ì„ ì¶”ì²œí•´ì£¼ëŠ” GPTì…ë‹ˆë‹¤."
            },
            {
                "role": "assistant",
                "content": "ì–´ë–¤ ìŒì•…ì„ ì¢‹ì•„í•˜ì‹œë‚˜ìš”?"
            }]
    for msg in st.session_state.messages:
        if msg["role"] != "system":
            chat_container.chat_message(msg["role"]).write(msg["content"])
    if st_prompt := st.chat_input(placeholder="ìŠ¬í”Œë• í™í•©ì„ ì¶°", key=st):
        st.session_state.messages.append(
            {
                "role": "user",
                "content": st_prompt
            })
        chat_container.chat_message("user").write(st_prompt)
        searched_result = vector_db.get_relevant_documents(st_prompt)[0]

        if not openai_api_key:
            st.info("Please add your OpenAI API key to continue.")
            st.stop()
        llm = ChatOpenAI(model_name="gpt-3.5-turbo",#"ft:gpt-3.5-turbo-0125:turingbio::93waZXFw",
                         openai_api_key=openai_api_key,
                         streaming=True)
        tools = [DuckDuckGoSearchRun(
                    api_wrapper=DuckDuckGoSearchAPIWrapper(time="d",
                                                           region="kr-kr",
                                                           max_results=20)),
                 DuckDuckGoSearchRun(
                    api_wrapper=DuckDuckGoSearchAPIWrapper(time="d",
                                                           region="en-en",
                                                           max_results=20)),
                 WikipediaQueryRun(
                    api_wrapper=WikipediaAPIWrapper()),
                 PubmedQueryRun(),
                 IonicTool().tool()] + load_tools(["arxiv"],)
        search_agent = initialize_agent(tools=tools,
                                        llm=llm,
                                        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
                                        # agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
                                        handle_parsing_errors=True,
                                        max_iterations=5,
                                        early_stopping_method="generate",
                                        return_intermediate_steps=True,
                                        # agent_kwargs={
                                            # "format_instructions": schema_therapy.format_instructions,
                                            # "system_message_prefix": schema_therapy.prefix_prompt,
                                            # "system_message_suffix": schema_therapy.suffix_prompt
                                            # }
                                        # max_execution_time=15
                                        )
        # st.write(search_agent.agent.__dir__())
        # st.write(AGENT_TO_CLASS[AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION])
        # st.write(search_agent.agent.tool_run_logging_kwargs())
        with chat_container.chat_message("assistant"):
            cfg = RunnableConfig()
            message_placeholder = st.empty()
            # cfg["callbacks"] = [StreamlitCallbackHandler(st.container(), 
            #                                              expand_new_thoughts=True)]
            search_instruction = copy.deepcopy(st.session_state.messages)
            search_instruction[-1]["content"] += f"\n(ìµœì‹  ë°œë§¤ ìŒì•… ì¶”ì²œ)"
            response = search_agent.invoke(search_instruction, 
                                           cfg, 
                                           chat_history=st.session_state.messages)
            # st.write(response)
            output = json.loads(response["output"])["action_input"] if "{" in response["output"]  else response["output"]
            full_msg = ""
            for o in output:
                full_msg += o
                message_placeholder.markdown(f'{full_msg}â–Œ')
            message_placeholder.markdown(full_msg)
            st.session_state.messages.append(
                    {
                        "role": "assistant",
                        "content": output
                    })