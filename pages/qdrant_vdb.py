import streamlit as st
import numpy as np
import uuid

from srcs.qdrant_vdb import get_rag_chain
from srcs.st_cache import init_vectorstore, get_or_create_eventloop

# LangGraph ì‹œê°í™”ë¥¼ ìœ„í•œ import ì¶”ê°€
import json
from pyvis.network import Network
import streamlit.components.v1 as components

get_or_create_eventloop()


st.set_page_config(
    page_title="Qdrant Vector DB Demo",
    page_icon="ğŸ”",
    layout="wide"
)

st.title('ğŸ” Qdrant Vector Database Demo')

st.markdown('''
## í”„ë¡œì íŠ¸ ì†Œê°œ

    Qdrant Vector Database í…ŒìŠ¤íŠ¸ í˜ì´ì§€
    ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ ê¸°ë³¸ì ì¸ CRUD ì‘ì—… í…ŒìŠ¤íŠ¸

## ê°œë°œ ë‚´ìš©
- ë²¡í„° ë°ì´í„° ìƒì„± ë° ì €ì¥
- ë²¡í„° ê²€ìƒ‰
- ì»¬ë ‰ì…˜ ê´€ë¦¬

## ì‚¬ìš© ê¸°ìˆ 
<img src="https://img.shields.io/badge/python-3776AB?style=for-the-badge&logo=python&logoColor=white">
<img src="https://img.shields.io/badge/github-181717?style=for-the-badge&logo=github&logoColor=white">
''', unsafe_allow_html=True)

vector_store = init_vectorstore()
chain = get_rag_chain(vector_store)

insert_section, info_section = st.columns(2)
with insert_section:
    # ë°ì´í„° ì…ë ¥ ì„¹ì…˜
    st.header("í…ìŠ¤íŠ¸ ë°ì´í„° ì…ë ¥")
    text_input = st.text_area("í…ìŠ¤íŠ¸ ì…ë ¥", height=100, 
        help="ì €ì¥í•˜ê³  ì‹¶ì€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì´ í…ìŠ¤íŠ¸ëŠ” ë²¡í„°ë¡œ ë³€í™˜ë˜ì–´ ì €ì¥ë©ë‹ˆë‹¤.")
    metadata = st.text_input("ë©”íƒ€ë°ì´í„° (ì„ íƒì‚¬í•­)", 
        help="í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì œëª©, ì¹´í…Œê³ ë¦¬ ë“±)")

if st.button("í…ìŠ¤íŠ¸ ì¶”ê°€"):
    # í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
    if vector_store.add_text(text_input.strip(), metadata):
        st.success("í…ìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        st.error("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
search_section, result_section = st.columns(2)
with search_section:
    # ê²€ìƒ‰ ì„¹ì…˜
    st.header("í…ìŠ¤íŠ¸ ê²€ìƒ‰")
    search_text = st.text_input(
        label="ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
        help="ì°¾ê³ ì í•˜ëŠ” í…ìŠ¤íŠ¸ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
with result_section:
    st.subheader("ê²€ìƒ‰ ê²°ê³¼")

if st.button("ê²€ìƒ‰"):
    if search_text.strip():
        # ê²€ìƒ‰ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        search_results = vector_store.search(search_text)
        if search_results:
            for result in search_results:
                with result_section:
                    with st.expander(f"ìœ ì‚¬ë„: {result['score']:.4f}"):
                        st.write("ğŸ“ í…ìŠ¤íŠ¸:")
                        st.write(result["text"])
                        st.write("â„¹ï¸ ë©”íƒ€ë°ì´í„°:")
                        st.write(result["metadata"])
        else:
            result_section.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        result_section.error("ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        
with info_section:
    # ì»¬ë ‰ì…˜ ì •ë³´ í‘œì‹œ
    st.header("ì»¬ë ‰ì…˜ ì •ë³´")
    collection_info = vector_store.get_collection_info()
    del collection_info["config"]
    st.json(collection_info)

# ì»¬ë ‰ì…˜ ì •ë³´ í‘œì‹œ ì„¹ì…˜ ì•„ë˜ì— ë‹¤ìŒ ì½”ë“œë¥¼ ì¶”ê°€
st.header("ğŸ’¬ RAG ì±„íŒ… í…ŒìŠ¤íŠ¸")
st.markdown("""
ì´ ì„¹ì…˜ì—ì„œëŠ” Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•œ RAG(Retrieval-Augmented Generation) ì±„íŒ…ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")

# ì‚¬ì´ë“œë°”ì— OpenAI API í‚¤ ì…ë ¥
# with st.sidebar:
#     openai_api_key = st.text_input("OpenAI API Key", type="password")
#     if not openai_api_key:
#         st.warning("Please enter your OpenAI API key to test the chat functionality.")

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):

    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()

        try:
            # RAG ì²´ì¸ ì‹¤í–‰
            
            response = chain.invoke({"question": prompt})
            # ì‘ë‹µ í‘œì‹œ
            message_placeholder.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
            
            # LangGraph ì‹œê°í™”
            if hasattr(chain, 'get_graph'):  # LangGraph ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
                st.subheader("ğŸ” ê²€ìƒ‰ ë° ì¶”ë¡  ê³¼ì •")
                
                # ê·¸ë˜í”„ ìƒì„±
                net = Network(height="500px", width="100%", bgcolor="#ffffff", font_color="black")
                
                # ë…¸ë“œì™€ ì—£ì§€ ì¶”ê°€
                graph_data = chain.get_graph()
                
                # ë…¸ë“œ ì¶”ê°€
                for node in graph_data['nodes']:
                    net.add_node(
                        node['id'], 
                        label=node['label'],
                        title=node.get('description', ''),
                        color=node.get('color', '#97c2fc')
                    )
                
                # ì—£ì§€ ì¶”ê°€
                for edge in graph_data['edges']:
                    net.add_edge(
                        edge['from'],
                        edge['to'],
                        title=edge.get('label', ''),
                        arrows='to'
                    )
                
                # HTML íŒŒì¼ë¡œ ì €ì¥
                net.save_graph("temp_graph.html")
                
                # Streamlitì— í‘œì‹œ
                with open("temp_graph.html", 'r', encoding='utf-8') as f:
                    html_string = f.read()
                
                components.html(html_string, height=600)
                
                # ìƒì„¸ ì •ë³´ í‘œì‹œ
                if 'process_details' in graph_data:
                    with st.expander("ğŸ“Š ìƒì„¸ ì²˜ë¦¬ ê³¼ì •"):
                        for step in graph_data['process_details']:
                            st.markdown(f"**{step['step']}**")
                            st.markdown(step['description'])
                            if 'data' in step:
                                st.json(step['data'])
            
        except Exception as e:
            st.error(f"Error generating response: {str(e)}")

# ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
if st.button("ì±„íŒ… ì´ˆê¸°í™”"):
    st.session_state.messages = []
    st.experimental_rerun()


