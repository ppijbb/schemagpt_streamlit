"""
Advanced RAG ì±—ë´‡ ì„œë¹„ìŠ¤ (Qdrant Vector DB).
Streamlit Cloud í˜¸í™˜: in-memory Qdrant, CPU ì„ë² ë”©, st.secrets API í‚¤.
"""
import asyncio
import os

import streamlit as st
from langchain_core.messages import HumanMessage

from srcs.qdrant_vdb import VectorStore, get_rag_chain
from srcs.st_cache import init_vectorstore

# Streamlit Cloud: ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì •
try:
    asyncio.get_running_loop()
except RuntimeError:
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

if __name__ == "__main__":
    st.set_page_config(
        page_title="Advanced RAG (Qdrant)",
        page_icon="ğŸ”—",
        layout="wide",
        initial_sidebar_state="auto",
    )

    st.title("ğŸ”— Advanced RAG ì±—ë´‡ ì„œë¹„ìŠ¤")
    st.caption("Qdrant in-memory + Multi-Query + BM25 Ensemble + Contextual Compression")

    # Streamlit Cloud: API í‚¤ëŠ” secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© (í•˜ë“œì½”ë”© ê¸ˆì§€)
    with st.sidebar:
        try:
            api_key = st.secrets.get("OPENAI_API_KEY", "")
        except Exception:
            api_key = os.environ.get("OPENAI_API_KEY", "")
        if not api_key:
            api_key = st.text_input(
                "OpenAI API Key (DDG ì±— ì‚¬ìš© ì‹œ í•„ìš”)",
                key="qdrant_openai_key",
                type="password",
            )
        if api_key:
            os.environ["OPENAI_API_KEY"] = api_key
        st.markdown("[Get an OpenAI API key](https://platform.openai.com/account/api-keys)")

    # VectorStoreëŠ” ë©”ëª¨ë¦¬ ë‚´ë¶€ (:memory:) â€” Cloud ì¬ì‹œì‘ ì‹œ ì´ˆê¸°í™”ë¨
    try:
        vectorstore: VectorStore = init_vectorstore()
    except Exception as e:
        st.error(f"VectorStore ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.stop()

    tab_add, tab_search, tab_rag = st.tabs(["ğŸ“„ ë¬¸ì„œ ì¶”ê°€", "ğŸ” ìœ ì‚¬ë„ ê²€ìƒ‰", "ğŸ’¬ RAG ì±—ë´‡"])

    with tab_add:
        st.subheader("ë¬¸ì„œ ì¶”ê°€")
        doc_text = st.text_area("ì €ì¥í•  í…ìŠ¤íŠ¸", height=120, key="qdrant_add_text")
        if st.button("ì €ì¥", key="qdrant_add_btn"):
            if doc_text and doc_text.strip():
                if vectorstore.add_text(doc_text.strip()):
                    st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.error("ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    with tab_search:
        st.subheader("ìœ ì‚¬ë„ ê²€ìƒ‰")
        query = st.text_input("ê²€ìƒ‰ ì¿¼ë¦¬", key="qdrant_search_query")
        limit = st.slider("ê²°ê³¼ ìˆ˜", 1, 20, 5, key="qdrant_search_limit")
        if st.button("ê²€ìƒ‰", key="qdrant_search_btn") and query:
            results = vectorstore.search(query, limit=limit)
            if results:
                for i, r in enumerate(results, 1):
                    with st.expander(f"#{i} (score: {r.get('score', 0):.4f})"):
                        st.write(r.get("text", ""))
                        if r.get("metadata"):
                            st.caption(str(r["metadata"]))
            else:
                st.info("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab_rag:
        st.subheader("RAG ì±—ë´‡")
        system_prompt = st.text_area(
            "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
            value="ë‹¹ì‹ ì€ ì£¼ì–´ì§„ Contextë¥¼ ë°”íƒ•ìœ¼ë¡œë§Œ ë‹µë³€í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. Contextì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.",
            height=80,
            key="qdrant_rag_system",
        )

        if "qdrant_rag_memory" not in st.session_state:
            from langchain.memory import ConversationBufferMemory
            st.session_state["qdrant_rag_memory"] = ConversationBufferMemory(
                return_messages=True,
                memory_key="history",
            )

        memory = st.session_state["qdrant_rag_memory"]
        if st.sidebar.button("ëŒ€í™” ì´ˆê¸°í™”", key="qdrant_rag_clear"):
            memory.clear()
            st.session_state.pop("qdrant_rag_memory", None)
            from langchain.memory import ConversationBufferMemory
            st.session_state["qdrant_rag_memory"] = ConversationBufferMemory(
                return_messages=True,
                memory_key="history",
            )
            st.rerun()

        chat_container = st.container()
        with chat_container:
            history = memory.load_memory_variables({}).get("history", [])
            for msg in history:
                role = "user" if isinstance(msg, HumanMessage) else "assistant"
                with st.chat_message(role):
                    st.write(msg.content if hasattr(msg, "content") else str(msg))

        if prompt := st.chat_input("RAG ì§ˆë¬¸ ì…ë ¥"):
            with st.chat_message("user"):
                st.write(prompt)
            try:
                chain = get_rag_chain(vectorstore, system_prompt.strip(), memory)
                response = chain.invoke({"question": prompt})
                memory.save_context({"input": prompt}, {"output": response})
                with st.chat_message("assistant"):
                    st.write(response)
                st.rerun()
            except Exception as e:
                st.error(f"ì˜¤ë¥˜: {e}")
