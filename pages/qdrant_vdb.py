import streamlit as st
import numpy as np
import uuid
import traceback

from srcs.qdrant_vdb import get_rag_chain
from srcs.st_cache import init_vectorstore, get_or_create_eventloop

# LangGraph ì‹œê°í™”ë¥¼ ìœ„í•œ import ì¶”ê°€
import json
from pyvis.network import Network
import streamlit.components.v1 as components
from srcs.st_utils import draw_mermaid
import streamlit_mermaid as stmd

get_or_create_eventloop()


st.set_page_config(
    page_title="Qdrant Vector DB",
    page_icon="ğŸ”",
    layout="wide"
)

st.title('ğŸ” Qdrant Vector Database')

st.markdown('''
## í”„ë¡œì íŠ¸ ì†Œê°œ

    Qdrant Vector Database í…ŒìŠ¤íŠ¸ í˜ì´ì§€
    ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ ê¸°ë³¸ì ì¸ CRUD ì‘ì—… í…ŒìŠ¤íŠ¸

## ê°œë°œ ë‚´ìš©
- ë²¡í„° ë°ì´í„° ìƒì„± ë° ì €ì¥
- ë²¡í„° ê²€ìƒ‰
- ì»¬ë ‰ì…˜ ê´€ë¦¬

## ì‚¬ìš© ê¸°ìˆ 
<img src="https://img.shields.io/badge/python-3776AB?style=for-the-badge&logo=python&logoColor=white">
<img src="https://img.shields.io/badge/github-181717?style=for-the-badge&logo=github&logoColor=white">
''', unsafe_allow_html=True)

vector_store = init_vectorstore()
chain = get_rag_chain(vector_store)

insert_section, info_section = st.columns(2)
with insert_section:
    # ë°ì´í„° ì…ë ¥ ì„¹ì…˜
    st.header("í…ìŠ¤íŠ¸ ë°ì´í„° ì…ë ¥")
    text_input = st.text_area(
        label="í…ìŠ¤íŠ¸ ì…ë ¥",
        height=100,
        help="ì €ì¥í•˜ê³  ì‹¶ì€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì´ í…ìŠ¤íŠ¸ëŠ” ë²¡í„°ë¡œ ë³€í™˜ë˜ì–´ ì €ì¥ë©ë‹ˆë‹¤.")
    metadata = st.text_input(
        label="ë©”íƒ€ë°ì´í„° (ì„ íƒì‚¬í•­)",
        help="í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì œëª©, ì¹´í…Œê³ ë¦¬ ë“±)")

if st.button("í…ìŠ¤íŠ¸ ì¶”ê°€"):
    # í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
    if vector_store.add_text(text_input.strip(), metadata):
        st.success("í…ìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        st.error("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
search_section, result_section = st.columns(2)
with search_section:
    # ê²€ìƒ‰ ì„¹ì…˜
    st.header("í…ìŠ¤íŠ¸ ê²€ìƒ‰")
    search_text = st.text_input(
        label="ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
        help="ì°¾ê³ ì í•˜ëŠ” í…ìŠ¤íŠ¸ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
with result_section:
    st.subheader("ê²€ìƒ‰ ê²°ê³¼")

if st.button("ê²€ìƒ‰"):
    if search_text.strip():
        # ê²€ìƒ‰ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        search_results = vector_store.search(search_text)
        if search_results:
            for result in search_results:
                with result_section:
                    with st.expander(f"ìœ ì‚¬ë„: {result['score']:.4f}"):
                        st.write("ğŸ“ í…ìŠ¤íŠ¸:")
                        st.write(result["text"])
                        st.write("â„¹ï¸ ë©”íƒ€ë°ì´í„°:")
                        st.write(result["metadata"])
        else:
            result_section.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        result_section.error("ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        
with info_section:
    # ì»¬ë ‰ì…˜ ì •ë³´ í‘œì‹œ
    st.header("ì»¬ë ‰ì…˜ ì •ë³´")
    collection_info = vector_store.get_collection_info()
    del collection_info["config"]
    st.json(collection_info)

# ì»¬ë ‰ì…˜ ì •ë³´ í‘œì‹œ ì„¹ì…˜ ì•„ë˜ì— ë‹¤ìŒ ì½”ë“œë¥¼ ì¶”ê°€
st.header("ğŸ’¬ RAG ì±„íŒ… í…ŒìŠ¤íŠ¸")
st.markdown("""
ì´ ì„¹ì…˜ì—ì„œëŠ” Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•œ RAG(Retrieval-Augmented Generation) ì±„íŒ…ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")

# ì‚¬ì´ë“œë°”ì— OpenAI API í‚¤ ì…ë ¥
# with st.sidebar:
#     openai_api_key = st.text_input("OpenAI API Key", type="password")
#     if not openai_api_key:
#         st.warning("Please enter your OpenAI API key to test the chat functionality.")

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "messages" not in st.session_state:
    st.session_state.messages = []

chat_section, graph_section = st.columns([0.7, 0.3])

with chat_section:
    # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):

        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            message_placeholder = st.empty()

            try:
                # RAG ì²´ì¸ ì‹¤í–‰
                response = chain.invoke({"question": prompt})
                # ì‘ë‹µ í‘œì‹œ
                message_placeholder.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
            except Exception as e:
                print(traceback.format_exc())
                st.error(f"Error generating response: {str(e)}")

    # ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ì±„íŒ… ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.experimental_rerun()

with graph_section:
    # LangGraph ì‹œê°í™”
    if hasattr(chain, 'get_graph'):  # LangGraph ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
        st.subheader("ğŸ” ê²€ìƒ‰ ë° ì¶”ë¡  ê³¼ì •")
        # ë…¸ë“œì™€ ì—£ì§€ ì¶”ê°€
        graph_data = chain.get_graph()
        # st.image(graph_data.draw_mermaid_png())
        stmd.st_mermaid(graph_data.draw_mermaid(), width="100%", height="800px")
        # draw_mermaid(graph_data.draw_mermaid())
        # ìƒì„¸ ì •ë³´ í‘œì‹œ
        if hasattr(graph_data, 'process_details'):
            with st.expander("ğŸ“Š ìƒì„¸ ì²˜ë¦¬ ê³¼ì •"):
                for step in graph_data.process_details:
                    st.markdown(f"**{step['step']}**")
                    st.markdown(step['description'])
                    if 'data' in step:
                        st.json(step['data'])
                    
