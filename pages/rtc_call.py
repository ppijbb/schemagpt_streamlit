import string

import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode

from srcs.rtc_call import VideoProcessor, AudioProcessor
from pages.rtc.config import RTC_CONFIGURATION


def show():
    # queries = st.experimental_get_query_params()
    # code = queries.get("code", None)[0]
    webrtc_ctx = webrtc_streamer(
        key=string.punctuation,
        mode=WebRtcMode.SENDRECV,
        rtc_configuration=RTC_CONFIGURATION,
        media_stream_constraints={
            "video": {
                # "frameRate": {
                #     "max": 60,
                #     "ideal": 0
                # },
                "width": {
                    "min": 640,
                    "max": 1024
                },
                "height": {
                    "min": 480,
                    "max": 768
                },
            },
            "audio": True
        },
        video_processor_factory=VideoProcessor,
        audio_processor_factory=AudioProcessor,
        async_processing=True,
        desired_playing_state=True,
        video_html_attrs={
            "style": {
                "width": "100%",
                "max-width": "768px",
                "margin": "0 auto",
                "justify-content": "center"
            },
            "controls": True,
            "autoPlay": True
        },
    )
    if webrtc_ctx.state.signalling:
        webrtc_ctx.video_processor.code = None


if __name__ == "__main__":
    st.set_page_config(page_title="facial emotion recognition",
                       page_icon="ğŸ« ",
                       layout="wide",
                       initial_sidebar_state="auto",)
    st.title('ğŸ˜„ğŸ˜‘ğŸ˜­ Facial Emotion Recognition')
    st.markdown('''
                
        ## í”„ë¡œì íŠ¸ ì†Œê°œ
        
            ëª¨ë°”ì¼ ì±„íŒ… ë° ìŒì„± ì±„íŒ…ì„ ìœ„í•œ WebRTC ì±„ë„
            ì„œë²„ì— ë¶€ë‹´ì„ ìµœì†Œí™”í•˜ëŠ” í†µì‹  ì—°ê²° ì‹¤í—˜


        ## ê°œë°œ ë‚´ìš©
        - í´ë¼ì´ì–¸íŠ¸ ìì›ì„ ì´ìš©í•˜ëŠ” ì±„íŒ… ë° ìŒì„± ë°ì´í„° ì†¡ìˆ˜ì‹  ì±„ë„
        - ë‹¤í™”ì ì±„íŒ… ì±„ë„ êµ¬í˜„
        - ì±„íŒ…ì— ëŒ€í•œ ë´‡ ì—°ê²° ê²€í† 
        ### NLP
        - ì±„íŒ… ì¤‘ íŠ¹ì •í•œ tool ì„ ë™ì‘ì‹œí‚¬ ìˆ˜ ìˆë„ë¡ Intent ë¶„ë¥˜ ëª¨ë¸ ê²€í† 
        - ì‹¤ì‹œê°„ ë¶€ì • ì±„íŒ… ê²€ìˆ˜ìš© ëª¨ë¸ ê²€í† 

        ### Audio Processing
        - ì˜¤ë””ì˜¤ íš¨ê³¼ ì ìš© 
        - ì˜¤ë””ì˜¤ ë¡œê·¸ ë° ì˜¤ë””ì˜¤ ì±„íŒ… ìš”ì•½ ê²€í† 
        - ë¶ˆëŸ‰ ì‚¬ìš©ì ëª©ì†Œë¦¬ì— ëŒ€í•œ ì˜¤ë””ì˜¤ VectorDB ê´€ë¦¬ ê²€í† 
        ### BackEnd
        - Firebase ì—ì„œ ì„œë¹„ìŠ¤ ì‹¤í—˜
        - ì„œë²„ ë¶€í•˜ì˜ ìµœì†Œí™” ì‹¤í—˜
 

        ## ì‚¬ìš© ê¸°ìˆ 
        <img src="https://img.shields.io/badge/python-3776AB?style=for-the-badge&logo=python&logoColor=white">
        <img src="https://img.shields.io/badge/github-181717?style=for-the-badge&logo=github&logoColor=white">
        <img src="https://img.shields.io/badge/fastapi-009688?style=for-the-badge&logo=fastapi&logoColor=white"> 
        <img src="https://img.shields.io/badge/numpy-013243?style=for-the-badge&logo=numpy&logoColor=black">
        <img src="https://img.shields.io/badge/pytorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=black"> 
        <img src="https://img.shields.io/badge/keras-D00000?style=for-the-badge&logo=keras&logoColor=black"> 
        <img src="https://img.shields.io/badge/opencv-5C3EE8?style=for-the-badge&logo=opencv&logoColor=black"> 
        ''', unsafe_allow_html=True)
    st.markdown("ë§ˆì´í¬ì™€ ì›¹ìº ì„ ì´ìš©í•©ë‹ˆë‹¤.")
    # with st.sidebar:
    #     st.page_link("pages/cardio.py",)
    #     st.page_link("pages/dep_peptide.py",)
    #     st.page_link("pages/facial.py",)
    # hide_menu_style = """
    #         <style>
    #         .css-1avcm0n {visibility: hidden;}
    #         .css-18ni7ap {visibility: hidden;}
    #         .block-container {padding: 0rem 1rem 10rem;}
    #         .block-container div {justify-content: center;gap: 0rem;}
    #         video {}
    #         </style>
    #         """
    # st.markdown(hide_menu_style, unsafe_allow_html=True)
    show()
